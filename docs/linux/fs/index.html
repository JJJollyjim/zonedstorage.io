<!doctype html>
<html lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.ff31de0ff">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Zoned Storage Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Zoned Storage Blog Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0DX1KGD5E4"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0DX1KGD5E4",{})</script><title data-react-helmet="true">File Systems | Zoned Storage</title><meta data-react-helmet="true" property="og:url" content="https://zonedstorage.io/docs/linux/fs"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="File Systems | Zoned Storage"><meta data-react-helmet="true" name="description" content="The dm-zoned device mapper target allows using any file"><meta data-react-helmet="true" property="og:description" content="The dm-zoned device mapper target allows using any file"><link data-react-helmet="true" rel="shortcut icon" href="/img/zs-logo.ico"><link data-react-helmet="true" rel="canonical" href="https://zonedstorage.io/docs/linux/fs"><link data-react-helmet="true" rel="alternate" href="https://zonedstorage.io/docs/linux/fs" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://zonedstorage.io/docs/linux/fs" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.30532e53.css">
<link rel="preload" href="/assets/js/runtime~main.ea9d92e0.js" as="script">
<link rel="preload" href="/assets/js/main.aa3c8835.js" as="script">
</head>
<body data-theme="light">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#main" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle" type="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_TMUO themedImage--light_4Vu1 navbar__logo"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_TMUO themedImage--dark_uzRr navbar__logo"><strong class="navbar__title">Zoned Storage</strong></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/introduction">Documentation</a><a class="navbar__item navbar__link" href="/docs/community/support">Community</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/westerndigitalcorporation/zonedstorage.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository">GitHub</a><div class="react-toggle displayOnlyInLargeViewport_cxYs react-toggle--disabled" role="button" tabindex="-1"><div class="react-toggle-track"><div class="react-toggle-track-check"><span class="toggle_iYfV">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_iYfV">ðŸŒž</span></div></div><div class="react-toggle-thumb"></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="dsla-search-wrapper"><div class="dsla-search-field"></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_TMUO themedImage--light_4Vu1 navbar__logo"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_TMUO themedImage--dark_uzRr navbar__logo"><strong class="navbar__title">Zoned Storage</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a class="menu__link navbar__link--active" href="/docs/introduction">Documentation</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/community/support">Community</a></li><li class="menu__list-item"><a href="https://github.com/westerndigitalcorporation/zonedstorage.io" target="_blank" rel="noopener noreferrer" class="menu__link header-github-link" aria-label="GitHub repository">GitHub</a></li></ul></div></div></div></nav><div class="main-wrapper docs-wrapper doc-page"><div class="docPage_lDyR"><div class="docSidebarContainer_0YBq" role="complementary"><div class="sidebar_a3j0"><div class="menu menu--responsive thin-scrollbar menu_cyFh"><button aria-label="Open menu" aria-haspopup="true" class="button button--secondary button--sm menu__button" type="button"><svg aria-label="Menu" class="sidebarMenuIcon_iZzd" width="24" height="24" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><ul class="menu__list"><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Introduction</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/introduction">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/introduction/zoned-storage">Zoned Storage Devices</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/introduction/smr">Shingled Magnetic Recording</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/introduction/zns">NVMe Zoned Namespaces (ZNS) SSDs</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Getting Started</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started/prerequisites">System Prerequisites</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started/nullblk">Zoned Block Device Emulation with nullblk</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started/smr-disk">Getting Started with SMR Hard-Disks</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started/smr-emulation">Getting Started with Emulated SMR Hard-Disks</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/getting-started/zns-emulation">Getting Started with Emulated NVMe ZNS Devices</a></li></ul></li><li class="menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#!">Linux Kernel Support</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/overview">Linux Kernel Zoned Storage Support</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/config">Kernel Configuration</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/zbd-api">Zoned Block Device User Interface</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/sched">Write Ordering Control</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/part">Zoned Block Device Partition Support</a></li><li class="menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/dm">Device Mapper</a></li><li class="menu__list-item"><a aria-current="page" class="menu__link menu__link--active active" tabindex="0" href="/docs/linux/fs">File Systems</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Applications</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/applications">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/applications/percona-server">Percona Server for MySQL</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/applications/zenfs">RocksDB with ZenFS</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">Tools and Libraries</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/util-linux">Linux System Utilities</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/zns">ZNS Tools</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/sg3utils">SCSI Generic Utilities</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/libzbc">libzbc User Library</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/libzbd">libzbd User Library</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/libnvme">libnvme User Library</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/tcmu-runner">tcmu-runner ZBC Disk Emulation</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tools/qemu">QEMU and KVM</a></li></ul></li><li class="menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#!">System Compliance Tests</a><ul class="menu__list"><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tests">Overview</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tests/zbc-tests">ZBC/ZAC Compliance Tests</a></li><li class="menu__list-item"><a class="menu__link" tabindex="-1" href="/docs/tests/blktests">Kernel Block Layer Tests</a></li></ul></li><li class="menu__list-item"><a class="menu__link" href="/docs/distributions/linux">Linux Distributions</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/benchmarking/benchmark">Benchmarking Zoned Block Devices</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/faq/faq">Frequently Asked Questions</a></li></ul></div></div></div><main class="docMainContainer_r8cw"><div class="container padding-vert--lg docItemWrapper_NJLN"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><header><h1 class="docTitle_-X99">File Systems</h1></header><div class="markdown"><p>The <a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device mapper target allows using any file
system with host managed zoned block devices by hiding the device sequential
write constraints. This is a simple solution to enable a file system use but not
necessarily the most efficient due to the potentially high overhead of a block
based zone reclaim process.</p><p>Supporting zoned block devices directly in a file system implementation can
lead to a more efficient zone reclaim processing as the file system metadata
and file abstraction provide more information on the usage and validity status
of storage blocks compared to the raw block device based approach.</p><p>Furthermore, a file system design may lend itself well to the sequential write
constraint of host managed zoned block devices. This is the case for
log-structured file systems such as <em>f2fs</em> and copy-on-write (CoW) file systems
such as <em>Btrfs</em>.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zonefs"></a>zonefs<a class="hash-link" href="#zonefs" title="Direct link to heading">#</a></h2><p>zonefs is a very simple file system exposing each zone of a zoned block device
as a file. <em>zonefs</em> is included with the upstream Linux kernel since version
5.6.0.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="overview"></a>Overview<a class="hash-link" href="#overview" title="Direct link to heading">#</a></h3><p>Unlike a regular POSIX-compliant file system with native zoned block device
support (e.g. <a href="/docs/linux/fs#f2fs"><em>f2fs</em></a>), <em>zonefs</em> does not hide the sequential write
constraint of zoned block devices to the user. Files representing sequential
write zones of the device must be written sequentially starting from the end of
the file (append only writes).</p><p>As such, <em>zonefs</em> is in essence closer to a raw block device access interface
than to a full-featured POSIX file system. The goal of <em>zonefs</em> is to simplify
the implementation of zoned block device support in applications by replacing
raw block device file accesses with the richer regular file API, avoiding
relying on direct block device file ioctls which may be more obscure to
developers. One example of this approach is the implementation of LSM
(log-structured merge) tree structures (such as used in RocksDB and LevelDB) on
zoned block devices by allowing SSTables to be stored in a zone file similarly
to a regular file system rather than as a range of sectors of the entire disk.
The introduction of the higher level construct &quot;one file is one zone&quot; can help
reducing the amount of changes needed in the application as well as introducing
support for different application programming languages.</p><p>The files representing zones are grouped by zone type, which are themselves
represented by sub-directories. This file structure is built entirely using
zone information provided by the device and so does not require any complex
on-disk metadata structure.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="on-disk-metadata"></a>On-Disk Metadata<a class="hash-link" href="#on-disk-metadata" title="Direct link to heading">#</a></h3><p><em>zonefs</em> on-disk metadata is composed only of an immutable super block which
persistently stores a magic number and optional feature flags and values. On
mount, <em>zonefs</em> uses the block layer API function <code>blkdev_report_zones()</code> to
obtain the device zone configuration and populates the mount point with a
static file tree solely based on this information. File sizes come from the
device zone type and write pointer position managed by the device itself.</p><p>The super block is always written on disk at sector 0. The first zone of the
device storing the super block is never exposed as a zone file by <em>zonefs</em>. If
the zone containing the super block is a sequential zone, the <code>mkzonefs</code> format
tool always &quot;finishes&quot; the zone, that is, it transitions the zone to a full
state to make it read-only, preventing any data write.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zone-type-sub-directories"></a>Zone Type Sub-Directories<a class="hash-link" href="#zone-type-sub-directories" title="Direct link to heading">#</a></h3><p>Files representing zones of the same type are grouped together under the same
sub-directory automatically created on mount.</p><p>For conventional zones, the sub-directory &quot;cnv&quot; is used. This directory is
however created if and only if the device has usable conventional zones. If
the device only has a single conventional zone at sector 0, the zone will not
be exposed as a file as it will be used to store the <em>zonefs</em> super block. For
such devices, the &quot;cnv&quot; sub-directory will not be created.</p><p>For sequential write zones, the sub-directory &quot;seq&quot; is used.</p><p>These two directories are the only directories that exist in <em>zonefs</em>. Users
cannot create other directories and cannot rename nor delete the &quot;cnv&quot; and
&quot;seq&quot; sub-directories.</p><p>The size of the directories indicated by the <code>st_size</code> field of <code>struct stat</code>,
obtained with the <code>stat()</code> or <code>fstat()</code> system calls, indicates the number of
files existing under the directory.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zone-files"></a>Zone files<a class="hash-link" href="#zone-files" title="Direct link to heading">#</a></h3><p>Zone files are named using the number of the zone they represent within the set
of zones of a particular type. That is, both the &quot;cnv&quot; and &quot;seq&quot; directories
contain files named &quot;0&quot;, &quot;1&quot;, &quot;2&quot;, ... The file numbers also represent
increasing zone start sector on the device.</p><p>All read and write operations to zone files are not allowed beyond the file
maximum size, that is, beyond the zone size. Any access exceeding the zone
size is failed with the <code>-EFBIG</code> error.</p><p>Creating, deleting, renaming or modifying any attribute of files is not allowed.</p><p>The number of blocks of a file as reported by <code>stat()</code> and <code>fstat()</code> indicates
the size of the file zone, or in other words, the maximum file size.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="conventional-zone-files"></a>Conventional Zone Files<a class="hash-link" href="#conventional-zone-files" title="Direct link to heading">#</a></h4><p>The size of conventional zone files is fixed to the size of the zone they
represent. Conventional zone files cannot be truncated.</p><p>These files can be randomly read and written using any type of I/O operation:
buffered I/Os, direct I/Os, memory mapped I/Os (mmap), etc. There are no I/O
constraint for these files beyond the file size limit mentioned above.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="sequential-zone-files"></a>Sequential zone files<a class="hash-link" href="#sequential-zone-files" title="Direct link to heading">#</a></h4><p>The size of sequential zone files grouped in the &quot;seq&quot; sub-directory represents
the file&#x27;s zone write pointer position relative to the zone start sector.</p><p>Sequential zone files can only be written sequentially, starting from the file
end, that is, write operations can only be append writes. Zonefs makes no
attempt at accepting random writes and will fail any write request that has a
start offset not corresponding to the end of the file, or to the end of the last
write issued and still in-flight (for asynchronous I/O operations).</p><p>Since dirty page writeback by the page cache does not guarantee a sequential
write pattern, <em>zonefs</em> prevents buffered writes and writeable shared mappings
on sequential files. Only direct I/O writes are accepted for these files.
<em>zonefs</em> relies on the sequential delivery of write I/O requests to the device
implemented by the block layer elevator (See <a href="/docs/linux/sched">Write Command Ordering</a>).</p><p>There are no restrictions on the type of I/O used for read operations in
sequential zone files. Buffered I/Os, direct I/Os and shared read mappings are
all accepted.</p><p>Truncating sequential zone files is allowed only down to 0, in which case, the
zone is reset to rewind the file zone write pointer position to the start of
the zone, or up to the zone size, in which case the file&#x27;s zone is transitioned
to the FULL state (finish zone operation).</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="format-options"></a>Format options<a class="hash-link" href="#format-options" title="Direct link to heading">#</a></h3><p>Several optional features of zonefs can be enabled at format time.</p><ul><li>Conventional zone aggregation: ranges of contiguous conventional zones can be
aggregated into a single larger file instead of the default one file per zone.</li><li>File ownership: The owner UID and GID of zone files is by default 0 (root)
but can be changed to any valid UID/GID.</li><li>File access permissions: the default 640 access permissions can be changed.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="io-error-handling"></a>IO error handling<a class="hash-link" href="#io-error-handling" title="Direct link to heading">#</a></h3><p>Zoned block devices may fail I/O requests for reasons similar to regular block
devices, e.g. due to bad sectors. However, in addition to such known I/O
failure pattern, the standards governing zoned block devices behavior define
additional conditions that can result in I/O errors.</p><ul><li><p>A zone may transition to the read-only condition:
While the data already written in the zone is still readable, the zone can
no longer be written. No user action on the zone (zone management command or
read/write access) can change the zone condition back to a normal read/write
state. While the reasons for the device to transition a zone to read-only
state are not defined by the standards, a typical cause for such transition
would be a defective write head on an HDD (all zones under this head are
changed to read-only).</p></li><li><p>A zone may transition to the offline condition:
An offline zone cannot be read nor written. No user action can transition an
offline zone back to an operational good state. Similarly to zone read-only
transitions, the reasons for a drive to transition a zone to the offline
condition are undefined. A typical cause would be a defective read-write head
on an HDD causing all zones on the platter under the broken head to be
inaccessible.</p></li><li><p>Unaligned write errors:
These errors result from the host issuing write requests with a start sector
that does not correspond to a zone write pointer position when the write
request is executed by the device. Even though <em>zonefs</em> enforces sequential
file write for sequential zones, unaligned write errors may still happen in
the case of a partial failure of a very large direct I/O operation split into
multiple BIOs/requests or asynchronous I/O operations.  If one of the write
request within the set of sequential write requests issued to the device
fails, all write requests queued after it will become unaligned and fail.</p></li><li><p>Delayed write errors:
Similarly to regular block devices, if the device side write cache is enabled,
write errors may occur in ranges of previously completed writes when the
device write cache is flushed, e.g. on <code>fsync()</code>.  Similarly to the previous
immediate unaligned write error case, delayed write errors can propagate
through a stream of cached sequential data for a zone causing all data to be
dropped after the sector that caused the error.</p></li></ul><p>All I/O errors detected by <em>zonefs</em> are notified to the user with an error code
return for the system call that triggered or detected the error. The recovery
actions taken by <em>zonefs</em> in response to I/O errors depend on the I/O type
(read vs write) and on the reason for the error (bad sector, unaligned writes or
zone condition change).</p><ul><li><p>For read I/O errors, <em>zonefs</em> does not execute any particular recovery action,
but only if the file zone is still in a good condition and there is no
inconsistency between the file inode size and its zone write pointer position.
If a problem is detected, I/O error recovery is executed (see below table).</p></li><li><p>For write I/O errors, <em>zonefs</em> I/O error recovery is always executed.</p></li><li><p>A zone condition change to read-only or offline also always triggers <em>zonefs</em>
I/O error recovery.</p></li></ul><p><em>zonefs</em> minimal I/O error recovery may change a file size and file access
permissions.</p><ul><li><p>File size changes:
Immediate or delayed write errors in a sequential zone file may cause the file
inode size to be inconsistent with the amount of data successfully written in
the file zone. For instance, the partial failure of a multi-BIO large write
operation will cause the zone write pointer to advance partially, even though
the entire write operation will be reported as failed to the user. In such
case, the file inode size must be advanced to reflect the zone write pointer
change and eventually allow the user to restart writing at the end of the
file.
A file size may also be reduced to reflect a delayed write error detected on
fsync(): in this case, the amount of data effectively written in the zone may
be less than originally indicated by the file inode size. After such I/O
error, <em>zonefs</em> always fixes the file inode size to reflect the amount of data
persistently stored in the file zone.</p></li><li><p>Access permission changes:
A zone condition change to read-only is indicated with a change in the file
access permissions to render the file read-only. This disables changes to the
file attributes and data modification. For offline zones, all permissions
(read and write) to the file are disabled.</p></li></ul><p>Further action taken by <em>zonefs</em> I/O error recovery can be controlled by the
user with the &quot;errors=xxx&quot; mount option. The table below summarizes the result
of <em>zonefs</em> I/O error processing depending on the mount option and on the zone
conditions.</p><center><table><thead><tr><th align="center">&quot;errors=xxx&quot; mount option</th><th align="center">Device zone condition</th><th align="center">File size</th><th align="center">File read</th><th align="center">File write</th><th align="center">Device read</th><th align="center">Device write</th></tr></thead><tbody><tr><td align="center">remount-ro</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">remount-ro</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">remount-ro</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-ro</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">zone-ro</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-ro</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-offline</td><td align="center">good</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">zone-offline</td><td align="center">read-only</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-offline</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">repair</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">repair</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">repair</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr></tbody></table></center><p>Further notes:</p><ul><li>The &quot;errors=remount-ro&quot; mount option is the default behavior of zonefs I/O
error processing if no errors mount option is specified.</li><li>With the &quot;errors=remount-ro&quot; mount option, the change of the file access
permissions to read-only applies to all files. The file system is remounted
read-only.</li><li>Access permission and file size changes due to the device transitioning zones
to the offline condition are permanent. Remounting or reformatting the device
with mkfs.zonefs (mkzonefs) will not change back offline zone files to a good
state.</li><li>File access permission changes to read-only due to the device transitioning
zones to the read-only condition are permanent. Remounting or reformatting
the device will not re-enable file write access.</li><li>File access permission changes implied by the remount-ro, zone-ro and
zone-offline mount options are temporary for zones in a good condition.
Unmounting and remounting the file system will restore the previous default
(format time values) access rights to the files affected.</li><li>The repair mount option triggers only the minimal set of I/O error recovery
actions, that is, file size fixes for zones in a good condition. Zones
indicated as being read-only or offline by the device still imply changes to
the zone file access permissions as noted in the table above.</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="mount-options"></a>Mount options<a class="hash-link" href="#mount-options" title="Direct link to heading">#</a></h3><p>zonefs define the &quot;errors=<em>behavior</em>&quot; mount option to allow the user to specify
zonefs behavior in response to I/O errors, inode size inconsistencies or zone
condition changes. The defined behaviors are as follow.</p><ul><li>remount-ro (default)</li><li>zone-ro</li><li>zone-offline</li><li>repair</li></ul><p>The run-time I/O error actions defined for each behavior are detailed in the
previous section. Mount time I/O errors will cause the mount operation to fail.
The handling of read-only zones also differs between mount-time and run-time.
If a read-only zone is found at mount time, the zone is always treated in the
same manner as offline zones, that is, all accesses are disabled and the zone
file size set to 0. This is necessary as the write pointer of read-only zones
is defined as invalib by the ZBC and ZAC standards, making it impossible to
discover the amount of data that has been written to the zone. In the case of a
read-only zone discovered at run-time, as indicated in the previous section.
the size of the zone file is left unchanged from its last updated value.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zonefs-user-space-tools"></a>Zonefs User Space Tools<a class="hash-link" href="#zonefs-user-space-tools" title="Direct link to heading">#</a></h3><p>The <code>mkzonefs</code> tool is used to format zoned block devices for use with <em>zonefs</em>.
This tool is available on <a href="https://github.com/westerndigitalcorporation/zonefs-tools" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><p><em>zonefs-tools</em> also includes a test suite which can be run against any zoned
block device, including
<a href="/docs/getting-started/nullblk"><em>nullblk</em> block device created with zoned mode</a>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="examples"></a>Examples<a class="hash-link" href="#examples" title="Direct link to heading">#</a></h3><p>The following formats a 15TB host-managed SMR HDD with 256 MB zones
with the conventional zones aggregation feature enabled::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mkzonefs -o aggr_cnv /dev/sdX</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># mount -t zonefs /dev/sdX /mnt</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/</span></div><div class="token-line" style="color:#393A34"><span class="token plain">total 0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">dr-xr-xr-x 2 root root     1 Nov 25 13:23 cnv</span></div><div class="token-line" style="color:#393A34"><span class="token plain">dr-xr-xr-x 2 root root 55356 Nov 25 13:23 seq</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The size of the zone files sub-directories indicate the number of files
existing for each type of zones. In this example, there is only one
conventional zone file (all conventional zones are aggregated under a single
file).</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/cnv</span></div><div class="token-line" style="color:#393A34"><span class="token plain">total 137101312</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 140391743488 Nov 25 13:23 0</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>This aggregated conventional zone file can be used as a regular file::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mkfs.ext4 /mnt/cnv/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># mount -o loop /mnt/cnv/0 /data</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The &quot;seq&quot; sub-directory grouping files for sequential write zones has in this
example 55356 zones::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># ls -lv /mnt/seq</span></div><div class="token-line" style="color:#393A34"><span class="token plain">total 14511243264</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 1</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 2</span></div><div class="token-line" style="color:#393A34"><span class="token plain">...</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 55354</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 55355</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>For sequential write zone files, the file size changes as data is appended at
the end of the file, similarly to any regular file system::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># dd if=/dev/zero of=/mnt/seq/0 bs=4096 count=1 conv=notrunc oflag=direct</span></div><div class="token-line" style="color:#393A34"><span class="token plain">1+0 records in</span></div><div class="token-line" style="color:#393A34"><span class="token plain">1+0 records out</span></div><div class="token-line" style="color:#393A34"><span class="token plain">4096 bytes (4.1 kB, 4.0 KiB) copied, 0.00044121 s, 9.3 MB/s</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 4096 Nov 25 13:23 /mnt/seq/0</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The written file can be truncated to the zone size, preventing any further
write operation::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># truncate -s 268435456 /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 268435456 Nov 25 13:49 /mnt/seq/0</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>Truncation to 0 size allows freeing the file zone storage space and restart
append-writes to the file::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># truncate -s 0 /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:49 /mnt/seq/0</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>Since files are statically mapped to zones on the disk, the number of blocks of
a file as reported by stat() and fstat() indicates the size of the file zone::</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># stat /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">File: /mnt/seq/0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Size: 0             Blocks: 524288     IO Block: 4096   regular empty file</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Device: 870h/2160d  Inode: 50431       Links: 1</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Access: (0640/-rw-r-----)  Uid: (    0/    root)   Gid: (    0/    root)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Access: 2019-11-25 13:23:57.048971997 +0900</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Modify: 2019-11-25 13:52:25.553805765 +0900</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Change: 2019-11-25 13:52:25.553805765 +0900</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Birth: -</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The number of blocks of the file (&quot;Blocks&quot;) in units of 512B blocks gives the
maximum file size of 524288 * 512 B = 256 MB, corresponding to the device zone
size in this example. Of note is that the &quot;IO block&quot; field always indicates the
minimum I/O size for writes and corresponds to the device physical sector size.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="f2fs"></a>f2fs<a class="hash-link" href="#f2fs" title="Direct link to heading">#</a></h2><p>The <em>Flash-Friendly File System</em> (<em>f2fs</em>) was designed on a basis of a
log-structured file system approach but modified to avoid the classical problems
of the traditional log-structured approach (e.g. The snowball effect of
wandering trees and the high cleaning overhead).</p><p><em>f2fs</em> supports various parameters not only for configuring on-disk layout but
also for selecting allocation and cleaning algorithms.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zoned-block-device-support"></a>Zoned Block Device Support<a class="hash-link" href="#zoned-block-device-support" title="Direct link to heading">#</a></h3><p>Zoned block device support was added to <em>f2fs</em> with kernel 4.10. Since <em>f2fs</em>
uses a metadata block on-disk format with fixed block location, only zoned block
devices which include conventional zones can be supported. Zoned devices composed
entirely of sequential zones cannot be used with <em>f2fs</em> as a standalone device
and require a multi-device setup to place metadata blocks on a randomly
writable storage. <em>f2fs</em> supports multi-device setup where multiple block device
address spaces are linearly concatenated to form a logically larger block
device. The <a href="/docs/linux/dm#dm-linear"><em>dm-linear</em></a> device mapper target can also be used
to create a logical device composed of conventional zones and sequential zones
suitable for <em>f2fs</em>.</p><p><em>f2fs</em> zoned block device support was achieved using the following principles.</p><ol><li><strong>Section Alignment</strong> In <em>f2fs</em>, a section is a group of fixed size
segments (2 MB). The number of segments in a section is determined to match
the zoned device zone size. For instance, with a 256 MB zone size, a section
contains 128 segments of 2MB.</li><li><strong>Forced LFS mode</strong> By default, <em>f2fs</em> tries to optimize block allocation to
avoid excessive append write by allowing some random writes within segments.
The LFS mode forces sequential writes to segments and the sequential use of
segments within sections, resulting in full compliance with zoned block
devices write constraint.</li><li><strong>Zone reset as discard operation</strong> Block <em>discard</em> (or <em>trim</em>) used to
indicate to a device that a block or range of blocks are no longer in use is
replaced with execution of a zone write pointer reset command when all blocks
of all segments of a section are free, allowing the section to be reused.</li></ol><p>Compared to a solution using the <em>dm-zoned</em> device mapper target, performance
of <em>f2fs</em> on zoned devices does not suffer from zone reclaim overhead as writes
are always sequential and do not require on-disk temporary buffering. <em>f2fs</em>
garbage collection (segment cleanup) will generate overhead only for workloads
frequently deleting file or modifying files data.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="zone-capacity-support"></a>Zone Capacity Support<a class="hash-link" href="#zone-capacity-support" title="Direct link to heading">#</a></h3><p>NVMe ZNS SSDs can have a per
<a href="/docs/introduction/zns#zone-capacity-and-zone-size">zone capacity that is smaller than the zone size</a>.
To support ZNS devices, <em>f2fs</em> ensures that block allocation and accounting
only considers the blocks in a zone that are within the zone capacity. This
support for NVMe ZNS zone capacity is available since Linux kernel version 5.10.</p><p>Additionally, <em>f2fs</em> volumes need some storage space that is randomly writable
to store and update in-place metadata blocks for the volume. Since NVMe zoned
namespaces do not have conventional zones, a <em>f2fs</em> volume cannot be
self-contained within a single NVMe zoned namespace. To format a <em>f2fs</em> volume
using a NVMe zoned namespace, a multi-device volume format must be used to
provide an additional regular block device to store the volume metadata blocks.
This additional regular block device can be either a regular namespace on
the same NVMe device or a regular namespace on another NVMe device.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="limitations"></a>Limitations<a class="hash-link" href="#limitations" title="Direct link to heading">#</a></h3><p><em>f2fs</em> uses 32-bits block numbers with a block size of 4 KB. This results in a
maximum volume size of 16 TB. Any device or combination of devices (for a
multi-device volume) with a total capacity larger than 16 TB cannot be used
with <em>f2fs</em>.</p><p>To overcome this limit, the <a href="/docs/linux/dm#dm-linear"><em>dm-linear</em></a> device mapper target
can be used to partition a zoned block device into serviceable smaller logical
devices.  This configuration must ensure that each logical device created is
assigned a sufficient amount of conventional zones to store <em>f2fs</em> fixed
location metadata blocks.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="usage-example-with-a-host-managed-smr-hdd"></a>Usage Example with a Host Managed SMR HDD<a class="hash-link" href="#usage-example-with-a-host-managed-smr-hdd" title="Direct link to heading">#</a></h3><p>To format a zoned block device with <em>mkfs.f2fs</em>, the option <code>-m</code> must be
specified.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mkfs.f2fs -m /dev/sdb</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">    f2fs-tools: mkfs.f2fs Ver: 1.12.0 (2018-11-12)</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Disable heap-based policy</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Debug level = 0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Trim is enabled</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/sdb] Disk Model: HGST HSH721415AL</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Host-managed zoned block device:</span></div><div class="token-line" style="color:#393A34"><span class="token plain">      55880 zones, 524 randomly writeable zones</span></div><div class="token-line" style="color:#393A34"><span class="token plain">      65536 blocks per zone</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Segments per section = 128</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Sections per zone = 1</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: sector size = 4096</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: total sectors = 3662151680 (14305280 MB)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: zone aligned segment0 blkaddr: 65536</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: format version with</span></div><div class="token-line" style="color:#393A34"><span class="token plain">  &quot;Linux version 5.0.16-300.fc30.x86_64 (mockbuild@bkernel03.phx2.fedoraproject.org) (gcc version 9.1.1 20190503 (Red Hat 9.1.1-1) (GCC)) #1 SMP Tue May 14 19:33:09 UTC 2019&quot;</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/sdb] Discarding device</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Discarded 14305280 MB</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision ratio = 0.600%</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision segments = 86254 (GC reserved = 43690)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: format successful</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>The formatted zoned block device can now be directly mounted without any other
setup necessary.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mount /dev/sdb /mnt</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="usage-example-with-a-nvme-zns-ssd"></a>Usage Example with a NVMe ZNS SSD<a class="hash-link" href="#usage-example-with-a-nvme-zns-ssd" title="Direct link to heading">#</a></h3><p>Unlike SMR hard-disks, the kernel does not select by default the <em>mq-deadline</em>
block IO scheduler for block devices representing NVMe zoned namespaces. To
ensure that the regular write operations used by <em>f2fs</em> are delivered to the
device in sequential order, the IO scheduler for the NVMe zoned namespace block
device must be set to <em>mq-deadline</em>. This is done with the following command.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># echo mq-deadline &gt; /sys/block/nvme1n1/queue/scheduler</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>Where /dev/nvme1n1 is the block device file of the zoned namespace that will be
used for the <em>f2fs</em> volume. Using this namespace, a multi-device <em>f2fs</em> volume
using an additional regular block device (<code>/dev/nvme0n1</code> in the following
example) can be formatted using the <em>-c</em> option of <em>mkfs.f2fs</em>, as shown in the
following example.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mkfs.f2fs -f -m -c /dev/nvme1n1 /dev/nvme0n1</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">        F2FS-tools: mkfs.f2fs Ver: 1.14.0 (2021-06-23)</span></div><div class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Disable heap-based policy</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Debug level = 0</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Trim is enabled</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Host-managed zoned block device:</span></div><div class="token-line" style="color:#393A34"><span class="token plain">      2048 zones, 0 randomly writeable zones</span></div><div class="token-line" style="color:#393A34"><span class="token plain">      524288 blocks per zone</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Segments per section = 1024</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Sections per zone = 1</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: sector size = 4096</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: total sectors = 1107296256 (4325376 MB)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: zone aligned segment0 blkaddr: 524288</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: format version with</span></div><div class="token-line" style="color:#393A34"><span class="token plain">  &quot;Linux version 5.13.0-rc6+ (user1@brahmaputra) (gcc (Ubuntu 10.3.0-1ubuntu1) 10.3.0, GNU ld (GNU Binutils for Ubuntu) 2.36.1) #2 SMP Fri Jun 18 16:45:29 IST 2021&quot;</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/nvme0n1] Discarding device</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: This device doesn&#x27;t support BLKSECDISCARD</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: This device doesn&#x27;t support BLKDISCARD</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/nvme1n1] Discarding device</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Discarded 4194304 MB</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision ratio = 3.090%</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision segments = 74918 (GC reserved = 40216)</span></div><div class="token-line" style="color:#393A34"><span class="token plain">Info: format successful</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><p>To mount the volume formatted with the above command, the regular block device
must be specified.</p><div class="codeBlockContainer_J+bg"><div class="codeBlockContent_csEI plaintext"><div tabindex="0" class="prism-code language-plaintext codeBlock_rtdJ thin-scrollbar"><div class="codeBlockLines_1zSZ" style="color:#393A34;background-color:#f6f8fa"><div class="token-line" style="color:#393A34"><span class="token plain"># mount -t f2fs /dev/nvme0n1 /mnt/f2fs/</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_M3SB">Copy</button></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="btrfs"></a>Btrfs<a class="hash-link" href="#btrfs" title="Direct link to heading">#</a></h2><p><em>Btrfs</em> is a file system based on the copy-on-write (CoW) principle resulting in
any block update to never be written in-place. Work is ongoing to add native ZBD
support by changing the block allocation algorithm and block IO issuing code.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="block-allocation-changes"></a>Block Allocation Changes<a class="hash-link" href="#block-allocation-changes" title="Direct link to heading">#</a></h3><p><em>Btrfs</em> block management relies on grouping of blocks into <em>block groups</em>, with
each group composed of one or more <em>device extent</em>. The device extents of a
block group may belong to different devices (e.g. In the case of a RAID volume).
ZBD support changes the default device extent size to the size of the device
zones so that all device extents are always aligned to a zone.</p><p>Allocation of blocks within a block group is changed so that the allocation is
always sequential from the beginning of the block group. To do so, an allocation
pointer is added to block groups and used as the allocation hint. The changes
also ensure that block freed below the allocation pointer are ignored, resulting
in sequential block allocation within each group regardless of the block group
usage.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="io-management"></a>I/O Management<a class="hash-link" href="#io-management" title="Direct link to heading">#</a></h3><p>While the introduction of the allocation pointer ensures that blocks are
allocated sequentially within groups, so sequentially within zones, I/Os to
write out newly allocated blocks may be issued out of order causing errors when
writing to sequential zones. This problem is solved by introducing a write I/O
request staging list to each block group. This list is used to delay the
execution of unaligned write requests within a block group.</p><p>The zones of a block group are reset to allow rewriting only when the block
group is being freed, that is, when all the blocks within the block group are
unused.</p><p>For <em>Btrfs</em> volumes composed of multiple disks, restrictions are added to ensure
that all disks have the same zone model and in the case of zoned block devices,
the same zone size. This matches the existing <em>Btrfs</em> constraint that all device
extents in a block group must have the same size.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="upstream-contribution"></a>Upstream Contribution<a class="hash-link" href="#upstream-contribution" title="Direct link to heading">#</a></h3><p><em>Btrfs</em> zoned block device support is still in development and will be available
in stable releases after the usual upstream review process completes.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="xfs"></a>XFS<a class="hash-link" href="#xfs" title="Direct link to heading">#</a></h2><p><em>XFS</em> currently does not support zoned block devices. The
<a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device mapper target must be used to enable zoned
device use with <em>XFS</em>.</p><p>An early <a href="http://xfs.org/images/f/f6/Xfs-smr-structure-0.2.pdf" target="_blank" rel="noopener noreferrer"> design document</a> discussed the development work necessary to
support host aware and host managed disks with <em>XFS</em>. Parts of this design have
already been implemented and included into the kernel stable releases (e.g. Per
inode reverse block mapping b-trees feature). However, more work is necessary to
fully support zoned block devices.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_WiXH" id="ext4"></a>ext4<a class="hash-link" href="#ext4" title="Direct link to heading">#</a></h2><p>describes
Attempts at improving <em>ext4</em> performance with host aware zoned block
devices using changes to the file system journal management are described in
in <a href="https://lwn.net/Articles/720226/" target="_blank" rel="noopener noreferrer">this article</a>.
The changes are small and succeed in maintaining good performance. However,
support for host managed zoned block devices is not provided as some fundamental
<em>ext4</em> design aspects cannot be easily changed to match host managed device
constraints.</p><p>These optimizations for host aware zoned block devices is a research work and is
not included in <em>ext4</em> stable kernel releases. <em>ext4</em> also does not support host
managed disks. Similarly to <em>XFS</em>, the <em>ext4</em> file system can however be used
together with the <a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device mapper target.</p></div></article><div class="margin-vert--lg"><nav class="pagination-nav" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/linux/dm"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Device Mapper</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/applications"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Applications Â»</div></a></div></nav></div></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#zonefs" class="table-of-contents__link">zonefs</a><ul><li><a href="#overview" class="table-of-contents__link">Overview</a></li><li><a href="#on-disk-metadata" class="table-of-contents__link">On-Disk Metadata</a></li><li><a href="#zone-type-sub-directories" class="table-of-contents__link">Zone Type Sub-Directories</a></li><li><a href="#zone-files" class="table-of-contents__link">Zone files</a></li><li><a href="#format-options" class="table-of-contents__link">Format options</a></li><li><a href="#io-error-handling" class="table-of-contents__link">IO error handling</a></li><li><a href="#mount-options" class="table-of-contents__link">Mount options</a></li><li><a href="#zonefs-user-space-tools" class="table-of-contents__link">Zonefs User Space Tools</a></li><li><a href="#examples" class="table-of-contents__link">Examples</a></li></ul></li><li><a href="#f2fs" class="table-of-contents__link">f2fs</a><ul><li><a href="#zoned-block-device-support" class="table-of-contents__link">Zoned Block Device Support</a></li><li><a href="#zone-capacity-support" class="table-of-contents__link">Zone Capacity Support</a></li><li><a href="#limitations" class="table-of-contents__link">Limitations</a></li><li><a href="#usage-example-with-a-host-managed-smr-hdd" class="table-of-contents__link">Usage Example with a Host Managed SMR HDD</a></li><li><a href="#usage-example-with-a-nvme-zns-ssd" class="table-of-contents__link">Usage Example with a NVMe ZNS SSD</a></li></ul></li><li><a href="#btrfs" class="table-of-contents__link">Btrfs</a><ul><li><a href="#block-allocation-changes" class="table-of-contents__link">Block Allocation Changes</a></li><li><a href="#io-management" class="table-of-contents__link">I/O Management</a></li><li><a href="#upstream-contribution" class="table-of-contents__link">Upstream Contribution</a></li></ul></li><li><a href="#xfs" class="table-of-contents__link">XFS</a></li><li><a href="#ext4" class="table-of-contents__link">ext4</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/introduction/zoned-storage">Introduction to Zoned Storage</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started/index">Getting Started with Zoned Storage</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://app.element.io/#/room/#zonedstorage-general:matrix.org" target="_blank" rel="noopener noreferrer" class="footer__link-item">Matrix</a></li><li class="footer__item"><a href="https://join.slack.com/t/zonedstorage/shared_invite/zt-uyfut5xe-nKajp9YRnEWqiD4X6RkTFw" target="_blank" rel="noopener noreferrer" class="footer__link-item">Slack</a></li><li class="footer__item"><a href="https://webchat.oftc.net/?channels=zonedstorage" target="_blank" rel="noopener noreferrer" class="footer__link-item">IRC @ OFTC</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/westerndigitalcorporation" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub Organization</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2021 Western Digital
	Corporation or its affiliates. All rights reserved.<br> By using this site, you agree to the <a href="https://www.westerndigital.com/legal/terms-of-use" target="_blank">Terms of Use</a> and <a href="https://www.westerndigital.com/legal/privacy-statement" target="_blank">Privacy Statement</a>.  All example scripts and program snippets on this site are licensed under the <a href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank">CCO 1.0 Universal</a> license.<br>This site is built with <a href="https://docusaurus.io/" target="_blank">Docusaurus</a>.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.ea9d92e0.js"></script>
<script src="/assets/js/main.aa3c8835.js"></script>
</body>
</html>