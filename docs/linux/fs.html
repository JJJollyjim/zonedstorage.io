<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-0DX1KGD5E4"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0DX1KGD5E4",{})</script><title data-react-helmet="true">File Systems | Zoned Storage</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://zonedstorage.io/docs/linux/fs"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="File Systems | Zoned Storage"><meta data-react-helmet="true" name="description" content="The dm-zoned device-mapper target makes it possible to"><meta data-react-helmet="true" property="og:description" content="The dm-zoned device-mapper target makes it possible to"><link data-react-helmet="true" rel="icon" href="/img/zs-logo.ico"><link data-react-helmet="true" rel="canonical" href="https://zonedstorage.io/docs/linux/fs"><link data-react-helmet="true" rel="alternate" href="https://zonedstorage.io/docs/linux/fs" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://zonedstorage.io/docs/linux/fs" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.1a239bed.css">
<link rel="preload" href="/assets/js/runtime~main.8df543a9.js" as="script">
<link rel="preload" href="/assets/js/main.fffd029c.js" as="script">
</head>
<body data-theme="light">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/zs-logo.png" alt="Zoned Storage Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Zoned Storage</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/introduction">Documentation</a><a class="navbar__item navbar__link" href="/docs/community/support">Community</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/westerndigitalcorporation/zonedstorage.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div><div class="dsla-search-wrapper"><div class="dsla-search-field" data-tags="default,docs-default-current"></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/introduction">Introduction</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/getting-started">Getting Started</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_VCh3" aria-current="page" href="/docs/linux">Linux Kernel Support</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux">Overview</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/overview">Linux Kernel Zoned Storage Support</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/config">Kernel Configuration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/zbd-api">Zoned Block Device User Interface</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/sched">Write Ordering Control</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/part">Zoned Block Device Partition Support</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/linux/dm">Device Mapper</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/linux/fs">File Systems</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/applications">Applications</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/tools">Tools and Libraries</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/tests">System Compliance Tests</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/distributions/linux">Linux Distributions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/benchmarking/benchmark">Benchmarking Zoned Block Devices</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/faq">Frequently Asked Questions</a></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><h1>File Systems</h1><p>The <a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device-mapper target makes it possible to
use any file system with host-managed zoned block devices. It does this by
hiding the device&#x27;s sequential write constraints. This solution is simple and
makes it possible to use file systems, but its potentially high overhead
during the block-based zone-reclamation process means that is not the
maximally efficient solution. </p><p>File systems whose implementations directly support zoned block devices have
more efficient zone-reclamation processing. This is because file systems that
directly support zoned block devices have metadata and file abstractions that
provide more information about the usage and validity of storage blocks than
do file systems that take the <em>dm-zoned</em>-block-based approach.</p><p>Some file systems are designed in such a way that they work well with the
sequential write constraint of host-managed zoned block devices. This is the
case for log-structured file systems such as <em>f2fs</em> and copy-on-write (CoW)
file systems such as <em>Btrfs</em>.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="zonefs">zonefs<a class="hash-link" href="#zonefs" title="Direct link to heading">â€‹</a></h2><p><em>zonefs</em> is a very simple file system that exposes each of the zones of a zoned
block device as a file. <em>zonefs</em> has been included with the upstream Linux
kernel since version 5.6.0.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="overview">Overview<a class="hash-link" href="#overview" title="Direct link to heading">â€‹</a></h3><p><em>zonefs</em> does not hide from the user the sequential write constraints of zoned
block devices. In this, it is unlike a regular POSIX-compliant file system
with native zoned-block device support (e.g. <a href="/docs/linux/fs#f2fs"><em>f2fs</em></a>). Files
that represent sequential write zones on the device must be written
sequentially, starting from the end of the file (these are &quot;append only&quot;
writes).</p><p><em>zonefs</em> is therefore more similar to a raw-block-device-access interface than
it is to a full-featured POSIX file system. The goal of <em>zonefs</em> is to
simplify the implementation of zoned block device support in applications, and
it aims to do this by replacing raw block device file accesses with the richer
regular-file API (which avoids relying on the possibly more obscure and
developer-unfriendly direct block device file ioctls). One example of this
approach is the implementation of LSM (log-structured merge) tree structures
(such as used in RocksDB and LevelDB) on zoned block devices: SSTables are
stored in a zone file in a way that is similar to the way a regular file
system works rather than as a range of sectors of the entire disk. The
introduction of the higher-level construct &quot;one file is one zone&quot; can reduce
the number of changes needed in the application, and also introduces support
for different application programming languages.</p><p>The files that represent zones are grouped by zone type, and those zone types
themselves are represented by sub-directories. This file structure is built
entirely using zone information that is provided by the device and therefore
does not require any complex on-disk metadata structure.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="on-disk-metadata">On-Disk Metadata<a class="hash-link" href="#on-disk-metadata" title="Direct link to heading">â€‹</a></h3><p><em>zonefs</em> on-disk metadata is composed only of an immutable super block which
persistently stores a magic number and optional feature flags and values. On
mount, <em>zonefs</em> uses the block layer API function <code>blkdev_report_zones()</code> to
obtain the device zone configuration and populates the mount point with a
static file tree that is based solely on this information. File sizes come
from the device zone type and the write-pointer position, both of which are
managed by the device itself. <em>zonefs</em> operates only based on information
from the device. <em>zonefs</em> does not have any metadata of its own.</p><p>The super block is always written on disk at sector 0. The first zone of the
device that stores the super block is never exposed as a zone file by
<em>zonefs</em>. If the zone that contains the super block is a sequential zone, the
<code>mkzonefs</code> format tool always &quot;finishes&quot; the zone (that is, it transitions the
zone to a full state to make it read-only, preventing any data write).</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zone-type-sub-directories">Zone Type Sub-Directories<a class="hash-link" href="#zone-type-sub-directories" title="Direct link to heading">â€‹</a></h3><p>Files that represent zones of the same type are grouped together under the same
sub-directory, which is automatically created on mount.</p><p>For conventional zones, the sub-directory &quot;cnv&quot; is used. This directory is
created only if the device has usable conventional zones. If the device has
only a single conventional zone at sector 0, the zone will not be exposed as a
file (because it will be used to store the <em>zonefs</em> super block). For such
devices, the &quot;cnv&quot; sub-directory will not be created.</p><p>For sequential write zones, the sub-directory &quot;seq&quot; is used.</p><p>These two directories are the only directories that exist in <em>zonefs</em>. Users
cannot create other directories and can neither rename nor delete the &quot;cnv&quot;
and &quot;seq&quot; sub-directories.</p><p>The size of the directories indicates the number of files that exist under
the directory. This size is indicated by the <code>st_size</code> field of <code>struct
stat</code>, which is obtained with the <code>stat()</code> or <code>fstat()</code> system calls.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zone-files">Zone files<a class="hash-link" href="#zone-files" title="Direct link to heading">â€‹</a></h3><p>Zone files are named using the number of the zone they represent within the
set of zones of a particular type. Both the &quot;cnv&quot; and &quot;seq&quot; directories
contain files named &quot;0&quot;, &quot;1&quot;, &quot;2&quot;, ... The file numbers also represent
increasing zone start sector on the device.</p><p>No read- and write-operations to zone files are allowed beyond the file
maximum size (that is, beyond the zone size). Any access that exceeds the zone
size fails with the <code>-EFBIG</code> error.</p><p>Creating, deleting, renaming and modifying any attribute of files is not
allowed.</p><p>The number of blocks of a file as reported by <code>stat()</code> and <code>fstat()</code> indicates
the size of the file zone (in other words, the maximum file size).</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="conventional-zone-files">Conventional Zone Files<a class="hash-link" href="#conventional-zone-files" title="Direct link to heading">â€‹</a></h4><p>The size of conventional zone files is fixed to the size of the zone that they
represent. Conventional zone files cannot be truncated.</p><p>These files can be randomly read and written using any type of I/O operation:
buffered I/Os, direct I/Os, memory mapped I/Os (mmap), etc. There are no I/O
constraints for these files beyond the file size limit mentioned above.</p><h4 class="anchor anchorWithStickyNavbar_mojV" id="sequential-zone-files">Sequential zone files<a class="hash-link" href="#sequential-zone-files" title="Direct link to heading">â€‹</a></h4><p>The size of sequential zone files that are grouped in the &quot;seq&quot; sub-directory
represents the file&#x27;s zone-write-pointer position relative to the zone start
sector.</p><p>Sequential zone files can be written only sequentially, starting from the file
end (that is, write operations can be only &quot;append writes&quot;). <code>zonefs</code> makes no
attempt to accept random writes and will fail any write request that has a
start offset that does not correspond to the end of the file, or to the end of
the last write issued and still in-flight (for asynchronous I/O operations).</p><p>Because dirty page writeback by the page cache does not guarantee a sequential
write pattern, <em>zonefs</em> prevents buffered writes and writeable shared mappings
on sequential files. Only direct I/O writes are accepted for these files.
<em>zonefs</em> relies on the sequential delivery of write I/O requests to the device
implemented by the block layer elevator (See
<a href="/docs/linux/sched">Write Command Ordering</a>).</p><p>There are no restrictions on the type of I/O used for read operations in
sequential zone files. Buffered I/Os, direct I/Os and shared read mappings are
all accepted.</p><p>Truncating sequential zone files is allowed only down to 0, in which case, the
zone is reset to rewind the file zone write pointer position to the start of
the zone, or up to the zone size, in which case the file&#x27;s zone is transitioned
to the FULL state (finish zone operation).</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="format-options">Format options<a class="hash-link" href="#format-options" title="Direct link to heading">â€‹</a></h3><p>Several optional features of <em>zonefs</em> can be enabled at format time.</p><ul><li>Conventional zone aggregation: ranges of contiguous conventional zones can
be aggregated into a single larger file instead of the default &quot;one file per
zone&quot;.</li><li>File ownership: By default, the owner UID and GID of zone files is 0 (root)
but can be changed to any valid UID/GID.</li><li>File access permissions: the default access permissions (640) can be changed.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="io-error-handling">IO error handling<a class="hash-link" href="#io-error-handling" title="Direct link to heading">â€‹</a></h3><p>Zoned block devices can fail I/O requests for reasons similar to the reasons
that regular block devices fail I/O requests, e.g. if there are bad sectors.
But the standards that govern the behavior of zoned block devices also define
additional conditions (in addition to these known I/O failure patterns) that
can result in I/O errors.</p><ul><li><p>A zone may transition to the read-only condition:
Although the data that is already written in the zone is still readable, the
zone can no longer be written. No user action on the zone (zone management
command or read/write access) can change the zone condition back to a
normal read/write state. While the reasons for the device to transition a
zone to read-only state are not defined by the standards, a typical cause
for such transition would be a defective write head on an HDD (all zones
under this head are changed to read-only).</p></li><li><p>A zone may transition to the offline condition:
An offline zone can be neither read nor written. No user action can
transition an offline zone back to an operational &quot;good state&quot;. Similar to
zone read-only transitions, the reasons that a drive transitions a zone
to the offline condition are undefined. A typical cause is (for example) a
defective read-write head on an HDD that causes all zones on the platter
under the broken head to be inaccessible.</p></li><li><p>Unaligned write errors:
These errors result from the device receiving a write request that has a
start sector that does not correspond to the write-pointer position of the
target zone. Although <em>zonefs</em> enforces sequential file write for
sequential zones, unaligned write errors can still happen in the case of a
partial failure of a very large direct I/O operation that is split into
multiple BIOs/requests or asynchronous I/O operations. If one of the write
requests within the set of sequential write requests that is issued to the
device fails, all write requests that are queued after it will become
unaligned and fail.</p></li><li><p>Delayed write errors:
As with regular block devices, if the device-side write cache is enabled,
write errors can occur in ranges of previously-completed writes when the
device write cache is flushed, e.g. on <code>fsync()</code>.  As in cases of immediate
unaligned write errors, delayed write errors can propagate through a stream
of cached sequential data for a zone, which can cause all data after the
sector that caused the error to be dropped. </p></li></ul><p>All I/O errors detected by <em>zonefs</em> are reported to the user with an error code
returned for the system call that triggered or detected the error. The recovery
actions taken by <em>zonefs</em> in response to I/O errors depend on the I/O type
(read vs write) and on the reason for the error (bad sector, unaligned writes or
zone condition change).</p><ul><li><p>For read I/O errors, <em>zonefs</em> takes recovery action action only if the file
zone is still in good condition and there is no inconsistency between the
file inode size and its zone write pointer position. If a problem is
detected, I/O error recovery is executed (see below table).</p></li><li><p>For write I/O errors, <em>zonefs</em> I/O error recovery is always executed.</p></li><li><p>A zone condition change to &quot;read-only&quot; or &quot;offline&quot; also always triggers
<em>zonefs</em> I/O error recovery.</p></li></ul><p><em>zonefs</em> minimal I/O error recovery can change a file&#x27;s size and its file
access permissions.</p><ul><li><p>File size changes:
Immediate or delayed write errors in a sequential zone file can cause the
file inode size to be inconsistent with the amount of data successfully
written in the file zone. For example, the partial failure of a multi-BIO
large write operation will cause the zone write pointer to advance partially,
even though the entire write operation is reported as failed to the user.
In such cases, the file inode size must be advanced to reflect the zone write
pointer change and eventually allow the user to restart writing at the end of
the file.
A file size may also be reduced to reflect a delayed write error detected on
fsync(): in this case, the amount of data effectively written in the zone may
be less than originally indicated by the file inode size. After any such I/O
error, <em>zonefs</em> always fixes the file inode size to reflect the amount of
data persistently stored in the file zone.</p></li><li><p>Access permission changes:
A zone condition change to read-only is indicated with a change in the file
access permissions, rendering the file read-only. This disables changes to
the file attributes and data modification. For offline zones, all permissions
(read and write) of the file are disabled.</p></li></ul><p>Further action taken by <em>zonefs</em> I/O error recovery can be controlled by the
user with the &quot;errors=xxx&quot; mount option. The table below summarizes the result
of <em>zonefs</em> I/O error processing, depending on the mount option and on the zone
conditions.</p><center><table><thead><tr><th align="center">&quot;errors=xxx&quot; mount option</th><th align="center">Device zone condition</th><th align="center">File size</th><th align="center">File read</th><th align="center">File write</th><th align="center">Device read</th><th align="center">Device write</th></tr></thead><tbody><tr><td align="center">remount-ro</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">remount-ro</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">remount-ro</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-ro</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">zone-ro</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-ro</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-offline</td><td align="center">good</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">zone-offline</td><td align="center">read-only</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">zone-offline</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">repair</td><td align="center">good</td><td align="center">fixed</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#00ff00">yes</span></td></tr><tr><td align="center">repair</td><td align="center">read-only</td><td align="center">as is</td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#00ff00">yes</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr><tr><td align="center">repair</td><td align="center">offline</td><td align="center">0</td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td><td align="center"><span style="color:#ff0000">no</span></td></tr></tbody></table></center><p>Further notes:</p><ul><li>The &quot;errors=remount-ro&quot; mount option is the default behavior of zonefs I/O
error processing if no errors mount option is specified.</li><li>With the &quot;errors=remount-ro&quot; mount option, the change of file access
permissions to &quot;read-only&quot; applies to all files. The file system is remounted
read-only.</li><li>Access permission and file-size changes caused by the device transitioning
zones to the offline condition are permanent. Remounting or reformatting the
device with mkfs.zonefs (mkzonefs) will not change offline zone files back
to a good state.</li><li>All file access permission changes to read-only that are due to the device
transitioning zones to the read-only condition are permanent. Remounting or
reformatting the device will not re-enable file write access.</li><li>File access permission changes implied by the &quot;remount-ro&quot;, &quot;zone-ro&quot; and
&quot;zone-offline&quot; mount options are temporary for zones in a good condition.
Unmounting and remounting the file system restores the previous default
(format time values) access rights to the files affected.</li><li>The repair mount option triggers only the minimal set of I/O error recovery
actions (that is, file size fixes for zones in a good condition). Zones
that are indicated as &quot;read-only&quot; or &quot;offline&quot; by the device still imply
changes to the zone file access permissions as noted in the table above.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="mount-options">Mount options<a class="hash-link" href="#mount-options" title="Direct link to heading">â€‹</a></h3><p><em>zonefs</em> defines the &quot;errors=<em>behavior</em>&quot; mount option to allow the user to
specify zonefs behavior in response to I/O errors, inode size inconsistencies
or zone condition changes. The defined behaviors are as follows.</p><ul><li>remount-ro (default)</li><li>zone-ro</li><li>zone-offline</li><li>repair</li></ul><p>The run-time I/O error actions defined for each behavior are detailed in
<a href="/docs/linux/fs#io-error-handling"><em>IO error handling</em></a>. Mount-time I/O errors cause
the mount operation to fail.</p><p>Read-only zones are handled differently at mount time than they are at
run time. If a read-only zone is found at mount time, the zone is always
treated in the same manner as offline zones (that is, all accesses are
disabled and the zone file size set to 0). This is necessary, because the write
pointer of read-only zones is defined as invalid by the ZBC and ZAC standards
(which makes it impossible to discover the amount of data that has been
written to the zone). In the case of a read-only zone that is discovered at
run-time, as indicated in <a href="/docs/linux/fs#io-error-handling"><em>IO error handling</em></a>,
the size of the zone file is left unchanged from its last updated value.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zonefs-user-space-tools">Zonefs User Space Tools<a class="hash-link" href="#zonefs-user-space-tools" title="Direct link to heading">â€‹</a></h3><p>The <code>mkzonefs</code> tool is used to format zoned block devices for use with <em>zonefs</em>.
This tool is available on <a href="https://github.com/westerndigitalcorporation/zonefs-tools" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><p><em>zonefs-tools</em> also includes a test suite that can be run against any zoned
block device, including
<a href="/docs/getting-started/nullblk"><em>nullblk</em> block device created with zoned mode</a>.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="examples">Examples<a class="hash-link" href="#examples" title="Direct link to heading">â€‹</a></h3><p>The following list of commands formats a 15TB host-managed SMR HDD with 256 MB
zones (with the conventional zones aggregation feature enabled):</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mkzonefs -o aggr_cnv /dev/sdX</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># mount -t zonefs /dev/sdX /mnt</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dr-xr-xr-x 2 root root     1 Nov 25 13:23 cnv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">dr-xr-xr-x 2 root root 55356 Nov 25 13:23 seq</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The size of the zone files&#x27; sub-directories indicates the number of files
that exist for each type of zone. In this example, there is only one
conventional zone file (all conventional zones are aggregated under a single
file):</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/cnv</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total 137101312</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 140391743488 Nov 25 13:23 0</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>This aggregated conventional zone file can be used as a regular file:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mkfs.ext4 /mnt/cnv/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># mount -o loop /mnt/cnv/0 /data</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The &quot;seq&quot; sub-directory, which groups files for sequential write zones, has
55356 zones in this example:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># ls -lv /mnt/seq</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">total 14511243264</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 2</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 55354</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:23 55355</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>For sequential write zone files, the file size changes as data is appended at
the end of the file. This is similar to the behavior of any regular file
system:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># dd if=/dev/zero of=/mnt/seq/0 bs=4096 count=1 conv=notrunc oflag=direct</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1+0 records in</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">1+0 records out</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">4096 bytes (4.1 kB, 4.0 KiB) copied, 0.00044121 s, 9.3 MB/s</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 4096 Nov 25 13:23 /mnt/seq/0</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The written file can be truncated to the zone size, which prevents any further
write operations:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># truncate -s 268435456 /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 268435456 Nov 25 13:49 /mnt/seq/0</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Truncation to 0 size allows freeing the file zone storage space and restarts
append-writes to the file:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># truncate -s 0 /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"># ls -l /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">-rw-r----- 1 root root 0 Nov 25 13:49 /mnt/seq/0</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Since files are statically mapped to zones on the disk, the number of blocks of
a file as reported by stat() and fstat() indicates the size of the file zone:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># stat /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">File: /mnt/seq/0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Size: 0             Blocks: 524288     IO Block: 4096   regular empty file</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Device: 870h/2160d  Inode: 50431       Links: 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Access: (0640/-rw-r-----)  Uid: (    0/    root)   Gid: (    0/    root)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Access: 2019-11-25 13:23:57.048971997 +0900</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Modify: 2019-11-25 13:52:25.553805765 +0900</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Change: 2019-11-25 13:52:25.553805765 +0900</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Birth: -</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The number of blocks of the file (&quot;Blocks&quot;) in units of 512B blocks gives the
maximum file size of 524288 * 512 B = 256 MB, which corresponds to the device
zone size in this example. Note that the &quot;IO block&quot; field always indicates the
minimum I/O size for writes and that it corresponds to the device&#x27;s physical
sector size.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="f2fs">f2fs<a class="hash-link" href="#f2fs" title="Direct link to heading">â€‹</a></h2><p>The <em>Flash-Friendly File System</em> (<em>f2fs</em>) was designed on the basis of a
log-structured file system approach, but was modified to avoid the classical
problems of the traditional log-structured approach (e.g. the snowball effect
of &quot;wandering trees&quot; and the high &quot;cleaning overhead&quot;).</p><p><em>f2fs</em> supports various parameters not only for configuring on-disk layout but
also for selecting allocation and cleaning algorithms.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zoned-block-device-support">Zoned Block Device Support<a class="hash-link" href="#zoned-block-device-support" title="Direct link to heading">â€‹</a></h3><p>Zoned block device support was added to <em>f2fs</em> with kernel 4.10. Because <em>f2fs</em>
uses a metadata-block on-disk format with fixed-block location, only zoned
block devices that include conventional zones are supported. Zoned devices
composed entirely of sequential zones cannot be used with <em>f2fs</em> as a
standalone device and they require a multi-device setup in order to place
metadata blocks on randomly writable storage. <em>f2fs</em> supports multi-device
setup where multiple block device address spaces are linearly concatenated to
form a logically larger block device. The <a href="/docs/linux/dm#dm-linear"><em>dm-linear</em></a>
device mapper target can also be used to create a logical device that is
composed of both conventional zones and sequential zones suitable for <em>f2fs</em>.</p><p><em>f2fs</em> zoned block device support was achieved using the following principles.</p><ol><li><strong>Section Alignment</strong> In <em>f2fs</em>, a section is a group of fixed-size
segments (2 MB). The number of segments in a section is determined to match
the zoned device zone size. For example: with a 256 MB zone size, a section
contains 128 segments of 2MB.</li><li><strong>Forced LFS mode</strong> By default, <em>f2fs</em> tries to optimize block allocation
(in order to avoid excessive append write) by allowing some random writes
within segments. The LFS mode forces sequential writes to segments and
forces the sequential use of segments within sections, which results in
full compliance with the zoned block device&#x27;s write constraint.</li><li><strong>Zone reset as discard operation</strong> In the past, block <em>discard</em> (or <em>trim</em>)
indicated to a device that a block or range of blocks are no longer in use.
This has been replaced with the execution of a &quot;zone write pointer reset&quot;
command when all blocks of all segments of a section are free. This allows
the section to be reused.</li></ol><p>Compared to a solution that uses the <em>dm-zoned</em> device mapper target,
the performance of <em>f2fs</em> on zoned devices does not suffer from &quot;zone reclaim
overhead&quot;, because writes are always sequential and do not require on-disk
temporary buffering. <em>f2fs</em> garbage collection (segment cleanup) generates
overhead only for workloads that frequently delete files or modify files&#x27; data.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zone-capacity-support">Zone Capacity Support<a class="hash-link" href="#zone-capacity-support" title="Direct link to heading">â€‹</a></h3><p>NVMe ZNS SSDs can have a per <a href="/docs/introduction/zns#zone-capacity-and-zone-size">zone capacity that is smaller than the zone
size</a>. To support ZNS devices,
<em>f2fs</em> ensures that block allocation and accounting considers only the blocks
in a zone that are within the zone&#x27;s capacity. This support for NVMe ZNS zone
capacity has been available since it was introduced in Linux kernel version
5.10.</p><p><em>f2fs</em> volumes need some storage space that is randomly writable in order
to store and update in-place metadata blocks for the volume. Since NVMe zoned
namespaces do not have conventional zones, a <em>f2fs</em> volume cannot be
self-contained within a single NVMe zoned namespace. To format an <em>f2fs</em> volume
using a NVMe zoned namespace, a multi-device volume format must be used in order
to provide an additional regular block device to store the volume metadata
blocks. This additional regular block device can be either a regular namespace
on the same NVMe device or a regular namespace on another NVMe device.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="limitations">Limitations<a class="hash-link" href="#limitations" title="Direct link to heading">â€‹</a></h3><p><em>f2fs</em> uses 32-bit block numbers with a block size of 4 KB. This results in a
maximum volume size of 16 TB. Any device or combination of devices (for a
multi-device volume) with a total capacity that is larger than 16 TB cannot
be used with <em>f2fs</em>.</p><p>To overcome this limit, the <a href="/docs/linux/dm#dm-linear"><em>dm-linear</em></a> device mapper
target can be used to partition a zoned block device into serviceable,
smaller logical devices. This configuration must ensure that each logical
device that is created is assigned a sufficient amount of conventional zones
to store <em>f2fs</em> fixed location metadata blocks.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-example-with-a-host-managed-smr-hdd">Usage Example with a Host Managed SMR HDD<a class="hash-link" href="#usage-example-with-a-host-managed-smr-hdd" title="Direct link to heading">â€‹</a></h3><p>To format a zoned block device with <em>mkfs.f2fs</em>, the option <code>-m</code> must be
specified:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mkfs.f2fs -m /dev/sdb</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    f2fs-tools: mkfs.f2fs Ver: 1.12.0 (2018-11-12)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Disable heap-based policy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Debug level = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Trim is enabled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/sdb] Disk Model: HGST HSH721415AL</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Host-managed zoned block device:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      55880 zones, 524 randomly writeable zones</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      65536 blocks per zone</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Segments per section = 128</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Sections per zone = 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: sector size = 4096</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: total sectors = 3662151680 (14305280 MB)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: zone aligned segment0 blkaddr: 65536</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: format version with</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;Linux version 5.0.16-300.fc30.x86_64 (mockbuild@bkernel03.phx2.fedoraproject.org) (gcc version 9.1.1 20190503 (Red Hat 9.1.1-1) (GCC)) #1 SMP Tue May 14 19:33:09 UTC 2019&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/sdb] Discarding device</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Discarded 14305280 MB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision ratio = 0.600%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision segments = 86254 (GC reserved = 43690)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: format successful</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The formatted zoned block device can now be directly mounted. No further
setup is necessary:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mount /dev/sdb /mnt</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-example-with-a-nvme-zns-ssd">Usage Example with a NVMe ZNS SSD<a class="hash-link" href="#usage-example-with-a-nvme-zns-ssd" title="Direct link to heading">â€‹</a></h3><p>Unlike SMR hard-disks, the kernel by default does not select the <em>mq-deadline</em>
block-IO scheduler for block devices that represent NVMe zoned namespaces. To
ensure that the regular write operations used by <em>f2fs</em> are delivered to the
device in sequential order, the IO scheduler for the NVMe zoned namespace block
device must be set to <em>mq-deadline</em>. This is done with the following command:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># echo mq-deadline &gt; /sys/block/nvme1n1/queue/scheduler</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>In the above command, <code>/dev/nvme1n1</code> is the block device file of the zoned
namespace that will be used for the <em>f2fs</em> volume. Using this namespace, a
multi-device <em>f2fs</em> volume that uses an additional regular block device
(<code>/dev/nvme0n1</code> in the following example) can be formatted using the <em>-c</em>
option of <em>mkfs.f2fs</em>, as shown in the following example:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mkfs.f2fs -f -m -c /dev/nvme1n1 /dev/nvme0n1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        F2FS-tools: mkfs.f2fs Ver: 1.14.0 (2021-06-23)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Disable heap-based policy</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Debug level = 0</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Trim is enabled</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Host-managed zoned block device:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      2048 zones, 0 randomly writeable zones</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      524288 blocks per zone</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Segments per section = 1024</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Sections per zone = 1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: sector size = 4096</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: total sectors = 1107296256 (4325376 MB)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: zone aligned segment0 blkaddr: 524288</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: format version with</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  &quot;Linux version 5.13.0-rc6+ (user1@brahmaputra) (gcc (Ubuntu 10.3.0-1ubuntu1) 10.3.0, GNU ld (GNU Binutils for Ubuntu) 2.36.1) #2 SMP Fri Jun 18 16:45:29 IST 2021&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/nvme0n1] Discarding device</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: This device doesn&#x27;t support BLKSECDISCARD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: This device doesn&#x27;t support BLKDISCARD</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: [/dev/nvme1n1] Discarding device</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Discarded 4194304 MB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision ratio = 3.090%</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: Overprovision segments = 74918 (GC reserved = 40216)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Info: format successful</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>To mount the volume formatted with the above command, the regular block device
must be specified:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mount -t f2fs /dev/nvme0n1 /mnt/f2fs/</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="btrfs">Btrfs<a class="hash-link" href="#btrfs" title="Direct link to heading">â€‹</a></h2><p><em>Btrfs</em> is a file system based on the copy-on-write (CoW) principle. This
principle has the result that no block update can be written in-place.
<em>Btrfs</em> currently supports zoned block devices, but that support is
experimental.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zoned-block-device-support-1">Zoned Block Device Support<a class="hash-link" href="#zoned-block-device-support-1" title="Direct link to heading">â€‹</a></h3><p>Zoned block device support was added to <em>btrfs</em> with kernel 5.12. Because
super-blocks are the only on-disk data structure with a fixed location in
<em>btrfs</em>, zoned block device support introduces the concept of log-structured
super-blocks to eliminate in-place updates (overwrites) of fixed super block
locations. Zoned mode reserves two consecutive zones to hold each of the
super-blocks (primary and backup super-blocks) in <em>btrfs</em>. When a new
super-block is written, it is appended to its respective super-block zone.
After the first super-block zone is filled, the next super block is written to
the second super-block zone and the first is reset. At mount time, <em>btrfs</em>
can find the latest version of the super-block by looking at the position of
the zone write pointer of the super-block zones. The most recent and valid
super-block is always the last  block stored before the write pointer
position.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="block-allocation-changes">Block Allocation Changes<a class="hash-link" href="#block-allocation-changes" title="Direct link to heading">â€‹</a></h3><p><em>Btrfs</em> block management relies on grouping blocks into <em>block groups</em>.
Each <em>block group</em> is composed of one or more <em>device extents</em>. The device
extents of a block group may belong to different devices (e.g. in the case
of a RAID volume). ZBD support changes the size of a device extent from its
default size to the size of the device zones. This ensures that all device
extents are always aligned to a zone.</p><p>Allocation of blocks within a block group is changed so that the allocation is
always sequential from the beginning of the block group. To do this, an
allocation pointer is added to block groups and used as the allocation hint.
These changes ensure that blocks freed below the allocation pointer are
ignored, which results in sequential block allocation within each group
regardless of the block group usage.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="io-management">I/O Management<a class="hash-link" href="#io-management" title="Direct link to heading">â€‹</a></h3><p>Although the introduction of the allocation pointer ensures that blocks are
allocated sequentially within groups (and therefore sequentially within zones),
I/O operations that write out newly allocated blocks can be issued out of
order, and this can cause errors when writing to sequential zones. This problem
is solved by introducing a &quot;write I/O request staging list&quot; to each block group.
This list is used to delay the execution of unaligned write requests within a
given block group.</p><p>The zones of a block group are reset to allow rewriting only when the block
group is free (that is, when all the blocks within the block group are
unused).</p><p>When dealing with <em>btrfs</em> volumes that are composed of multiple disks,
restrictions are added to ensure that all the disks have the same zone model
(and in the case of zoned block devices, the same zone size). This matches the
existing <em>btrfs</em> constraint that dictates that all device extents in a block
group must have the same size.</p><p>All writes to data block groups use <a href="/docs/introduction/zns#zone-append">Zone Append
writing</a>, which makes it possible to maintain
a high queue depth without violating the device zone&#x27;s sequential write
constraints. Every write to dedicated meta-data block groups is serialized
with a file-system-global zoned metadata I/O lock.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="zone-capacity-support-1">Zone Capacity Support<a class="hash-link" href="#zone-capacity-support-1" title="Direct link to heading">â€‹</a></h3><p>NVMe ZNS SSDs can have a per <a href="/docs/introduction/zns#zone-capacity-and-zone-size">zone capacity that is smaller than the zone
size</a>.  To support ZNS
devices, <em>btrfs</em> ensures that block allocation and accounting considers only
the blocks in a zone that are within the zone capacity. This support for NVMe
ZNS zone capacity has been available since Linux kernel version 5.16. Also,
since kernel 5.16, <em>btrfs</em> keeps track of the number of active zones on
a device and issues &quot;Zone Finish&quot; commands as needed.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="limitations-1">Limitations<a class="hash-link" href="#limitations-1" title="Direct link to heading">â€‹</a></h3><p>Not all features currently available in <em>btrfs</em> are supported in the current
zoned mode of the file-system.</p><p>These unavailable features include:</p><ul><li>RAID Support</li><li>NOCOW Support</li><li>Support for fallocate(2)</li><li>Mixed data and meta-data block groups</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="system-requirements">System Requirements<a class="hash-link" href="#system-requirements" title="Direct link to heading">â€‹</a></h3><p>In order to use <em>btrfs</em> on zoned block devices, the following minimum system
requirements must be met:</p><ul><li>Linux kernel 5.12 (for SMR) or 5.16 (for NVMe ZNS)</li><li><em>btrfs-progs</em> 5.12 (for SMR) or 5.15 (for NVMe ZNS)</li><li><em>util-linux</em> 2.38</li></ul><p>The source code for <em>btrfs-progs</em> <a href="https://github.com/kdave/btrfs-progs" target="_blank" rel="noopener noreferrer">is hosted on GitHub</a>. More information on <em>util-linux</em> can be
found <a href="/docs/tools/util-linux">here</a>.</p><p>If a kernel supports <em>btrfs</em> on a zoned block device, it will automatically
select the <em>mq_deadline</em> block IO scheduler by default. This ensures <a href="/docs/linux/sched">write
ordering correctness</a> for any SMR hard-disk that is used in a zoned
<em>btrfs</em> volume.</p><p>As in the case of <a href="/docs/linux/fs#usage-example-with-a-nvme-zns-ssd"><em>f2fs</em> use with an NVMe ZNS
SSD</a>, the <em>mq-deadline</em> scheduler must be
set manually to ensure that the regular write operations used by <em>btrfs</em> are
delivered to the device in sequential order. For a NVMe zoned namespace device
<em>/dev/nvmeXnY</em>, this is done with the following command:</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># echo mq-deadline &gt; /sys/block/nvmeXnY/queue/scheduler</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>Alternatively, the following udev rule can be used to automatically set the
<em>mq-deadline</em> scheduler for all zoned block devices that have been formatted
with btrfs.</p><div class="codeBlockContainer_I0IT language-plain theme-code-block"><div class="codeBlockContent_wNvx plain"><pre tabindex="0" class="prism-code language-plain codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">SUBSYSTEM!=&quot;block&quot;, GOTO=&quot;btrfs_end&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ACTION!=&quot;add|change&quot;, GOTO=&quot;btrfs_end&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ENV{ID_FS_TYPE}!=&quot;btrfs&quot;, GOTO=&quot;btrfs_end&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">ATTR{queue/zoned}==&quot;host-managed&quot;, ATTR{queue/scheduler}=&quot;mq-deadline&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">LABEL=&quot;btrfs_end&quot;</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h3 class="anchor anchorWithStickyNavbar_mojV" id="usage-example-with-a-host-managed-smr-hdd-1">Usage example with a Host Managed SMR HDD<a class="hash-link" href="#usage-example-with-a-host-managed-smr-hdd-1" title="Direct link to heading">â€‹</a></h3><p>To format a zoned block device with <em>mkfs.btrfs</em>, the <code>-m single</code> and <code>-d
single</code> options must be specified, because no block group profile other
than &quot;single&quot; is currently supported.</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mkfs.btrfs -m single -d single /dev/sda</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">btrfs-progs v5.15.1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">See http://btrfs.wiki.kernel.org for more information.</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Zoned: /dev/sda: host-managed device detected, setting zoned feature</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Resetting device zones /dev/sda (74508 zones) ...</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">NOTE: several default settings have changed in version 5.15, please make sure</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      this does not affect your deployments:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      - DUP for metadata (-m dup)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      - enabled no-holes (-O no-holes)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      - enabled free-space-tree (-R free-space-tree)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Label:              (null)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">UUID:               7ffa00fe-c6a3-4c6c-890f-858e17118c66</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Node size:          16384</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Sector size:        4096</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Filesystem size:    18.19TiB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Block group profiles:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Data:             single          256.00MiB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Metadata:         single          256.00MiB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  System:           single          256.00MiB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">SSD detected:       no</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Zoned device:       yes</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  Zone size:        256.00MiB</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Incompat features:  extref, skinny-metadata, no-holes, zoned</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Runtime features:   free-space-tree</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Checksum:           crc32c</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Number of devices:  1</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Devices:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">   ID        SIZE  PATH</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    1    18.19TiB  /dev/sda</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><p>The formatted block device can now be directly mounted. No other setup is
necessary.</p><div class="codeBlockContainer_I0IT language-plaintext theme-code-block"><div class="codeBlockContent_wNvx plaintext"><pre tabindex="0" class="prism-code language-plaintext codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain"># mount /dev/sda /mnt</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><h2 class="anchor anchorWithStickyNavbar_mojV" id="xfs">XFS<a class="hash-link" href="#xfs" title="Direct link to heading">â€‹</a></h2><p><em>XFS</em> currently does not support zoned block devices. The
<a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device mapper target must be used to enable
zoned device use with <em>XFS</em>.</p><p>An early <a href="http://xfs.org/images/f/f6/Xfs-smr-structure-0.2.pdf" target="_blank" rel="noopener noreferrer"> design document</a> discussed the development work necessary
to support host aware and host managed disks with <em>XFS</em>. Parts of this design
have already been implemented and included into the kernel stable releases
(e.g. the &quot;per inode reverse block mapping b-trees&quot; feature). However, more
work is necessary to fully support zoned block devices.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="ext4">ext4<a class="hash-link" href="#ext4" title="Direct link to heading">â€‹</a></h2><p>Attempts at improving <em>ext4</em> performance with host aware zoned block devices by
making changes to the file system journal management are described in in <a href="https://lwn.net/Articles/720226/" target="_blank" rel="noopener noreferrer">this article</a>. These
changes are small and succeed in maintaining good performance. However, support
for host managed zoned block devices is not provided, because some of the
fundamental aspects of <em>ext4</em> design cannot easily be changed to match host
managed device constraints.</p><p>The field of host optimizations for host aware zoned block devices remains in
the research phase and is not included in <em>ext4</em> stable kernel releases. It
should also be noted that <em>ext4</em> does not support host managed disks. As with
<em>XFS</em>, however, the <em>ext4</em> file system can be used together with the
<a href="/docs/linux/dm#dm-zoned"><em>dm-zoned</em></a> device mapper target.</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/linux/dm"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Device Mapper</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/applications"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Overview</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#zonefs" class="table-of-contents__link toc-highlight">zonefs</a><ul><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#on-disk-metadata" class="table-of-contents__link toc-highlight">On-Disk Metadata</a></li><li><a href="#zone-type-sub-directories" class="table-of-contents__link toc-highlight">Zone Type Sub-Directories</a></li><li><a href="#zone-files" class="table-of-contents__link toc-highlight">Zone files</a></li><li><a href="#format-options" class="table-of-contents__link toc-highlight">Format options</a></li><li><a href="#io-error-handling" class="table-of-contents__link toc-highlight">IO error handling</a></li><li><a href="#mount-options" class="table-of-contents__link toc-highlight">Mount options</a></li><li><a href="#zonefs-user-space-tools" class="table-of-contents__link toc-highlight">Zonefs User Space Tools</a></li><li><a href="#examples" class="table-of-contents__link toc-highlight">Examples</a></li></ul></li><li><a href="#f2fs" class="table-of-contents__link toc-highlight">f2fs</a><ul><li><a href="#zoned-block-device-support" class="table-of-contents__link toc-highlight">Zoned Block Device Support</a></li><li><a href="#zone-capacity-support" class="table-of-contents__link toc-highlight">Zone Capacity Support</a></li><li><a href="#limitations" class="table-of-contents__link toc-highlight">Limitations</a></li><li><a href="#usage-example-with-a-host-managed-smr-hdd" class="table-of-contents__link toc-highlight">Usage Example with a Host Managed SMR HDD</a></li><li><a href="#usage-example-with-a-nvme-zns-ssd" class="table-of-contents__link toc-highlight">Usage Example with a NVMe ZNS SSD</a></li></ul></li><li><a href="#btrfs" class="table-of-contents__link toc-highlight">Btrfs</a><ul><li><a href="#zoned-block-device-support-1" class="table-of-contents__link toc-highlight">Zoned Block Device Support</a></li><li><a href="#block-allocation-changes" class="table-of-contents__link toc-highlight">Block Allocation Changes</a></li><li><a href="#io-management" class="table-of-contents__link toc-highlight">I/O Management</a></li><li><a href="#zone-capacity-support-1" class="table-of-contents__link toc-highlight">Zone Capacity Support</a></li><li><a href="#limitations-1" class="table-of-contents__link toc-highlight">Limitations</a></li><li><a href="#system-requirements" class="table-of-contents__link toc-highlight">System Requirements</a></li><li><a href="#usage-example-with-a-host-managed-smr-hdd-1" class="table-of-contents__link toc-highlight">Usage example with a Host Managed SMR HDD</a></li></ul></li><li><a href="#xfs" class="table-of-contents__link toc-highlight">XFS</a></li><li><a href="#ext4" class="table-of-contents__link toc-highlight">ext4</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/introduction/zoned-storage">Introduction to Zoned Storage</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/getting-started">Getting Started with Zoned Storage</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://app.element.io/#/room/#zonedstorage-general:matrix.org" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Matrix<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://join.slack.com/t/zonedstorage/shared_invite/zt-uyfut5xe-nKajp9YRnEWqiD4X6RkTFw" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Slack<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://webchat.oftc.net/?channels=zonedstorage" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>IRC @ OFTC<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/westerndigitalcorporation" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub Organization<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022 Western Digital
	Corporation or its affiliates. All rights reserved.<br> By using this site, you agree to the <a href="https://www.westerndigital.com/legal/terms-of-use" target="_blank">Terms of Use</a> and <a href="https://www.westerndigital.com/legal/privacy-statement" target="_blank">Privacy Statement</a>.  All example scripts and program snippets on this site are licensed under the <a href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank">CCO 1.0 Universal</a> license.<br>This site is built with <a href="https://docusaurus.io/" target="_blank">Docusaurus</a>.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.8df543a9.js"></script>
<script src="/assets/js/main.fffd029c.js"></script>
</body>
</html>